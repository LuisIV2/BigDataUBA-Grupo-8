{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29cecd37-bd2a-4be6-8199-784e16ff6f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Valores √∫nicos en 'ocupacion': [nan  1.  3.  4.  0.]\n",
      "\n",
      "üìä Frecuencia de clases:\n",
      "ocupacion\n",
      "NaN    3213\n",
      "1.0    2407\n",
      "3.0    2357\n",
      "4.0     644\n",
      "0.0     119\n",
      "Name: count, dtype: int64\n",
      "‚ùå No hay suficientes clases (0 y 1) para entrenar el modelo log√≠stico.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m X \u001b[38;5;241m=\u001b[39m modelo[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medad2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meduc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmujer\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     75\u001b[0m y \u001b[38;5;241m=\u001b[39m modelo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocupacion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 76\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m444\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Tabla de diferencia de medias\u001b[39;00m\n\u001b[0;32m     79\u001b[0m media_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedia Train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2780\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2781\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2782\u001b[0m )\n\u001b[0;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2410\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2407\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2414\u001b[0m     )\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "base['ocupacion'] = base['ESTADO'].replace({1: 1, 2: 0})\n",
    "\n",
    "print(\"üîç Valores √∫nicos en 'ocupacion':\", base['ocupacion'].unique())\n",
    "print(\"\\nüìä Frecuencia de clases:\")\n",
    "print(base['ocupacion'].value_counts(dropna=False))\n",
    "\n",
    "modelo = base[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']]\n",
    "modelo = modelo[modelo['ocupacion'].isin([0, 1])]\n",
    "modelo = modelo.dropna()\n",
    "\n",
    "if modelo['ocupacion'].nunique() < 2:\n",
    "    print(\"‚ùå No hay suficientes clases (0 y 1) para entrenar el modelo log√≠stico.\")\n",
    "else:\n",
    "    X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "    y = modelo['ocupacion']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Entrenar modelo\n",
    "    modelo_rl = LogisticRegression(max_iter=1000)\n",
    "    modelo_rl.fit(X_train, y_train)\n",
    "\n",
    "    # Predicciones\n",
    "    y_pred = modelo_rl.predict(X_test)\n",
    "    y_prob = modelo_rl.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    #Resultados\n",
    "    print(\"\\nüìå Matriz de Confusi√≥n:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    print(f\"\\n‚úÖ Precisi√≥n del modelo: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "    print(f\"üìê AUC (√Årea bajo la curva ROC): {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "\n",
    "    #Curva ROC\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_prob):.2f}\", color='navy')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.title(\"üìä Curva ROC - Modelo Log√≠stico\")\n",
    "    plt.xlabel(\"Tasa de Falsos Positivos (FPR)\")\n",
    "    plt.ylabel(\"Tasa de Verdaderos Positivos (TPR)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar datos\n",
    "datos = pd.read_csv(\"C:/Users/Urano/Downloads/base_respondieron_patagonia.csv\", low_memory=False)\n",
    "\n",
    "# Variables: edad, edad^2, educaci√≥n, mujer, ocupaci√≥n\n",
    "datos['edad'] = pd.to_numeric(datos['ch06'], errors='coerce')\n",
    "datos['edad2'] = datos['edad'] ** 2\n",
    "datos['educ'] = pd.to_numeric(datos['pp07h'], errors='coerce')\n",
    "datos['mujer'] = datos['ch04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})\n",
    "\n",
    "# Filtrar datos v√°lidos (solo ocupados y desocupados)\n",
    "modelo = datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']]\n",
    "modelo = modelo[modelo['ocupacion'].isin([0,1])]\n",
    "modelo = modelo.dropna()\n",
    "\n",
    "# Dividir train/test con semilla 444\n",
    "X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "y = modelo['ocupacion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=444)\n",
    "\n",
    "# Tabla de diferencia de medias\n",
    "media_train = X_train.mean().rename(\"Media Train\")\n",
    "media_test = X_test.mean().rename(\"Media Test\")\n",
    "diferencia = (media_train - media_test).rename(\"Diferencia\")\n",
    "\n",
    "tabla_dif = pd.concat([media_train, media_test, diferencia], axis=1)\n",
    "print(\"üìä Tabla de diferencia de medias entre entrenamiento y testeo:\")\n",
    "print(tabla_dif.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba334169-94ee-4ff4-a5b8-80b09e255bd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m y \u001b[38;5;241m=\u001b[39m modelo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocupacion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# --- Dividir en train/test ---\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     30\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m444\u001b[39m\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# --- Tabla de diferencia de medias ---\u001b[39;00m\n\u001b[0;32m     34\u001b[0m medias_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedia Train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2780\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2781\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2782\u001b[0m )\n\u001b[0;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2410\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2407\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2414\u001b[0m     )\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Cargar base unificada ---\n",
    "ruta = \"C:/Users/Urano/Downloads/base_respondieron_patagonia.csv\"\n",
    "datos = pd.read_csv(ruta, low_memory=False)\n",
    "\n",
    "# --- Crear variables ---\n",
    "datos['edad'] = pd.to_numeric(datos['CH06'], errors='coerce')\n",
    "datos['edad2'] = datos['edad'] ** 2\n",
    "datos['mujer'] = datos['CH04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['educ'] = pd.to_numeric(datos['PP07H'], errors='coerce')\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})  # Ocupado (1) vs desocupado (0)\n",
    "\n",
    "# --- Eliminar filas con NaN en variables clave ---\n",
    "modelo = datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']].dropna()\n",
    "\n",
    "# --- Filtrar s√≥lo observaciones con ocupacion 0 o 1 ---\n",
    "modelo = modelo[modelo['ocupacion'].isin([0, 1])]\n",
    "\n",
    "# --- Separar en X e y ---\n",
    "X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "y = modelo['ocupacion']\n",
    "\n",
    "# --- Dividir en train/test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=444\n",
    ")\n",
    "\n",
    "# --- Tabla de diferencia de medias ---\n",
    "medias_train = X_train.mean().rename(\"Media Train\")\n",
    "medias_test = X_test.mean().rename(\"Media Test\")\n",
    "diferencias = (medias_train - medias_test).rename(\"Diferencia\")\n",
    "\n",
    "tabla_dif = pd.concat([medias_train, medias_test, diferencias], axis=1)\n",
    "\n",
    "print(\"üìä Tabla de diferencias de medias entre Train y Test:\\n\")\n",
    "print(tabla_dif.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d748af-9fff-4b75-bef9-2c65de453649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Columnas disponibles en tu dataset:\n",
      "\n",
      "['nro_hogar', 'componente', 'h15', 'ano4', 'trimestre', 'region', 'mas_500', 'aglomerado', 'pondera', 'ch03', 'ch04', 'ch06', 'ch07', 'ch08', 'ch09', 'ch10', 'ch11', 'ch12', 'ch13', 'ch14', 'ch15', 'ch15_cod', 'ch16', 'ch16_cod', 'nivel_ed', 'ESTADO', 'cat_ocup', 'cat_inac', 'pp02c1', 'pp02c2', 'pp02c3', 'pp02c4', 'pp02c5', 'pp02c6', 'pp02c7', 'pp02c8', 'pp02e', 'pp02h', 'pp02i', 'pp03c', 'pp03d', 'pp3e_tot', 'pp3f_tot', 'pp03g', 'pp03h', 'pp03i', 'pp03j', 'intensi', 'pp04a', 'pp04b_cod', 'pp04b1', 'pp04b2', 'pp04b3_mes', 'pp04b3_ano', 'pp04b3_dia', 'pp04c', 'pp04c99', 'pp04d_cod', 'pp04g', 'pp05b2_mes', 'pp05b2_ano', 'pp05b2_dia', 'pp05c_1', 'pp05c_2', 'pp05c_3', 'pp05e', 'pp05f', 'pp05h', 'pp06a', 'pp06c', 'pp06d', 'pp06e', 'pp06h', 'pp07a', 'pp07c', 'pp07d', 'pp07e', 'pp07f1', 'pp07f2', 'pp07f3', 'pp07f4', 'pp07f5', 'pp07g1', 'pp07g2', 'pp07g3', 'pp07g4', 'pp07g_59', 'pp07h', 'pp07i', 'pp07j', 'pp07k', 'pp08d1', 'pp08d4', 'pp08f1', 'pp08f2', 'pp08j1', 'pp08j2', 'pp08j3', 'pp09a', 'pp09a_esp', 'pp09b', 'pp09c', 'pp09c_esp', 'pp10a', 'pp10c', 'pp10d', 'pp10e', 'pp11a', 'pp11b_cod', 'pp11b1', 'pp11b2_mes', 'pp11b2_ano', 'pp11b2_dia', 'pp11c', 'pp11c99', 'pp11d_cod', 'pp11g_ano', 'pp11g_mes', 'pp11g_dia', 'pp11l', 'pp11l1', 'pp11m', 'pp11n', 'pp11o', 'pp11p', 'pp11q', 'pp11r', 'pp11s', 'pp11t', 'p21', 'decocur', 'idecocur', 'rdecocur', 'gdecocur', 'pdecocur', 'adecocur', 'tot_p12', 'p47t', 'decindr', 'idecindr', 'rdecindr', 'gdecindr', 'pdecindr', 'adecindr', 'v2_m', 'v3_m', 'v4_m', 'v5_m', 'v8_m', 'v9_m', 'v10_m', 'v11_m', 'v12_m', 'v18_m', 'v19_am', 'v21_m', 't_vi', 'itf', 'decifr', 'idecifr', 'rdecifr', 'gdecifr', 'pdecifr', 'adecifr', 'IPCF', 'deccfr', 'ideccfr', 'rdeccfr', 'gdeccfr', 'pdeccfr', 'adeccfr', 'pj1_1', 'pj2_1', 'pj3_1', 'idimpp', 'ano', 'ANO4', 'TRIMESTRE', 'NRO_HOGAR', 'COMPONENTE', 'H15', 'REGION', 'MAS_500', 'AGLOMERADO', 'PONDERA', 'CH03', 'CH04', 'CH05', 'CH06', 'CH07', 'CH08', 'CH09', 'CH10', 'CH11', 'CH12', 'CH13', 'CH14', 'CH15', 'CH15_COD', 'CH16', 'CH16_COD', 'NIVEL_ED', 'CAT_OCUP', 'CAT_INAC', 'IMPUTA', 'PP02C1', 'PP02C2', 'PP02C3', 'PP02C4', 'PP02C5', 'PP02C6', 'PP02C7', 'PP02C8', 'PP02E', 'PP02H', 'PP02I', 'PP03C', 'PP03D', 'PP3E_TOT', 'PP3F_TOT', 'PP03G', 'PP03H', 'PP03I', 'PP03J', 'INTENSI', 'PP04A', 'PP04B_COD', 'PP04B1', 'PP04B2', 'PP04B3_MES', 'PP04B3_ANO', 'PP04B3_DIA', 'PP04C', 'PP04C99', 'PP04D_COD', 'PP04G', 'PP05B2_MES', 'PP05B2_ANO', 'PP05B2_DIA', 'PP05C_1', 'PP05C_2', 'PP05C_3', 'PP05E', 'PP05F', 'PP05H', 'PP06A', 'PP06C', 'PP06D', 'PP06E', 'PP06H', 'PP07A', 'PP07C', 'PP07D', 'PP07E', 'PP07F1', 'PP07F2', 'PP07F3', 'PP07F4', 'PP07F5', 'PP07G1', 'PP07G2', 'PP07G3', 'PP07G4', 'PP07G_59', 'PP07H', 'PP07I', 'PP07J', 'PP07K', 'PP08D1', 'PP08D4', 'PP08F1', 'PP08F2', 'PP08J1', 'PP08J2', 'PP08J3', 'PP09A', 'PP09A_ESP', 'PP09B', 'PP09C', 'PP09C_ESP', 'PP10A', 'PP10C', 'PP10D', 'PP10E', 'PP11A', 'PP11B_COD', 'PP11B1', 'PP11B2_MES', 'PP11B2_ANO', 'PP11B2_DIA', 'PP11C', 'PP11C99', 'PP11D_COD', 'PP11G_ANO', 'PP11G_MES', 'PP11G_DIA', 'PP11L', 'PP11L1', 'PP11M', 'PP11N', 'PP11O', 'PP11P', 'PP11Q', 'PP11R', 'PP11S', 'PP11T', 'P21', 'DECOCUR', 'IDECOCUR', 'RDECOCUR', 'GDECOCUR', 'PDECOCUR', 'ADECOCUR', 'PONDIIO', 'TOT_P12', 'P47T', 'DECINDR', 'IDECINDR', 'RDECINDR', 'GDECINDR', 'PDECINDR', 'ADECINDR', 'PONDII', 'V2_M', 'V3_M', 'V4_M', 'V5_M', 'V8_M', 'V9_M', 'V10_M', 'V11_M', 'V12_M', 'V18_M', 'V19_AM', 'V21_M', 'T_VI', 'ITF', 'DECIFR', 'IDECIFR', 'RDECIFR', 'GDECIFR', 'PDECIFR', 'ADECIFR', 'DECCFR', 'IDECCFR', 'RDECCFR', 'GDECCFR', 'PDECCFR', 'ADECCFR', 'PONDIH']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ruta = \"C:/Users/Urano/Downloads/base_respondieron_patagonia.csv\"\n",
    "datos = pd.read_csv(ruta, low_memory=False)\n",
    "\n",
    "print(\"üìã Columnas disponibles en tu dataset:\\n\")\n",
    "print(datos.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8be7f273-12b6-42d2-a1f5-b3b3d62154dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m X \u001b[38;5;241m=\u001b[39m modelo[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medad\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124medad2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meduc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmujer\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m     22\u001b[0m y \u001b[38;5;241m=\u001b[39m modelo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mocupacion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 23\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m444\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Tabla de diferencia de medias\u001b[39;00m\n\u001b[0;32m     26\u001b[0m media_train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedia Train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2780\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2777\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2779\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2780\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2781\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m   2782\u001b[0m )\n\u001b[0;32m   2784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2410\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2407\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2413\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2414\u001b[0m     )\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar datos\n",
    "datos = pd.read_csv(\"C:/Users/Urano/Downloads/base_respondieron_patagonia.csv\", low_memory=False)\n",
    "\n",
    "# Variables: edad, edad^2, educaci√≥n, mujer, ocupaci√≥n\n",
    "datos['edad'] = pd.to_numeric(datos['ch06'], errors='coerce')\n",
    "datos['edad2'] = datos['edad'] ** 2\n",
    "datos['educ'] = pd.to_numeric(datos['pp07h'], errors='coerce')\n",
    "datos['mujer'] = datos['ch04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})\n",
    "\n",
    "# Filtrar datos v√°lidos (solo ocupados y desocupados)\n",
    "modelo = datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']]\n",
    "modelo = modelo[modelo['ocupacion'].isin([0,1])]\n",
    "modelo = modelo.dropna()\n",
    "\n",
    "# Dividir train/test con semilla 444\n",
    "X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "y = modelo['ocupacion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=444)\n",
    "\n",
    "# Tabla de diferencia de medias\n",
    "media_train = X_train.mean().rename(\"Media Train\")\n",
    "media_test = X_test.mean().rename(\"Media Test\")\n",
    "diferencia = (media_train - media_test).rename(\"Diferencia\")\n",
    "\n",
    "tabla_dif = pd.concat([media_train, media_test, diferencia], axis=1)\n",
    "print(\"üìä Tabla de diferencia de medias entre entrenamiento y testeo:\")\n",
    "print(tabla_dif.round(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b30f017a-090d-438e-a907-c46f03b169e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Filas v√°lidas despu√©s de limpieza: 0\n",
      "‚ùå No hay datos v√°lidos. Revis√° que las variables no tengan todos valores faltantes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar base\n",
    "datos = pd.read_csv(\"C:/Users/Urano/Downloads/base_respondieron_patagonia.csv\", low_memory=False)\n",
    "\n",
    "# Variables clave\n",
    "datos['edad'] = pd.to_numeric(datos['ch06'], errors='coerce')\n",
    "datos['edad2'] = datos['edad'] ** 2\n",
    "datos['educ'] = pd.to_numeric(datos['pp07h'], errors='coerce')\n",
    "datos['mujer'] = datos['ch04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})  # 1 = ocupado, 2 = desocupado\n",
    "\n",
    "# Selecci√≥n del modelo\n",
    "modelo = datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']]\n",
    "modelo = modelo[modelo['ocupacion'].isin([0, 1])]  # Solo ocupados/desocupados\n",
    "modelo = modelo.dropna()\n",
    "\n",
    "# Verificar cantidad de filas\n",
    "print(f\"üìä Filas v√°lidas despu√©s de limpieza: {len(modelo)}\")\n",
    "\n",
    "# Si hay datos, continuar\n",
    "if len(modelo) == 0:\n",
    "    print(\"‚ùå No hay datos v√°lidos. Revis√° que las variables no tengan todos valores faltantes.\")\n",
    "else:\n",
    "    # Divisi√≥n train/test\n",
    "    X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "    y = modelo['ocupacion']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=444)\n",
    "\n",
    "    # Diferencia de medias\n",
    "    media_train = X_train.mean().rename(\"Media Train\")\n",
    "    media_test = X_test.mean().rename(\"Media Test\")\n",
    "    diferencia = (media_train - media_test).rename(\"Diferencia\")\n",
    "\n",
    "    tabla_dif = pd.concat([media_train, media_test, diferencia], axis=1)\n",
    "    print(\"üìä Tabla de diferencia de medias entre entrenamiento y testeo:\")\n",
    "    print(tabla_dif.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8305d343-3dac-4520-9c98-41d54f2798df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Valores NO nulos por variable:\n",
      "edad         3213\n",
      "educ         2254\n",
      "mujer        3264\n",
      "ocupacion    8787\n",
      "dtype: int64\n",
      "\n",
      "üìå Valores √∫nicos en 'ocupacion':\n",
      "ocupacion\n",
      "1                   2407\n",
      "3                   2357\n",
      "Inactivo            1307\n",
      "Ocupado             1238\n",
      "4                    644\n",
      "Menor de 10 a√±os     600\n",
      "Desocupado           119\n",
      "2                    115\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar base\n",
    "datos = pd.read_csv(\"C:/Users/Urano/Downloads/base_respondieron_patagonia.csv\", low_memory=False)\n",
    "\n",
    "# Crear columnas necesarias con nombres crudos\n",
    "datos['edad'] = pd.to_numeric(datos['ch06'], errors='coerce')\n",
    "datos['educ'] = pd.to_numeric(datos['pp07h'], errors='coerce')\n",
    "datos['mujer'] = datos['ch04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})  # solo 1 (ocupado) y 2 (desocupado)\n",
    "\n",
    "# Revisar cantidad de valores v√°lidos\n",
    "print(\"üîé Valores NO nulos por variable:\")\n",
    "print(datos[['edad', 'educ', 'mujer', 'ocupacion']].notnull().sum())\n",
    "\n",
    "print(\"\\nüìå Valores √∫nicos en 'ocupacion':\")\n",
    "print(datos['ocupacion'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148beaff-8df9-433f-ba25-f8ea2c00d752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Valores NO nulos por variable:\n",
      "edad         5523\n",
      "edad2        5523\n",
      "educ         2407\n",
      "mujer        5523\n",
      "ocupacion    5523\n",
      "dtype: int64\n",
      "\n",
      "üìå Valores √∫nicos en 'ocupacion':\n",
      "ocupacion\n",
      "NaN    3264\n",
      "1.0    2407\n",
      "3.0    2357\n",
      "4.0     644\n",
      "2.0     115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Filas v√°lidas despu√©s de limpieza: 2407\n",
      "\n",
      "üìä Tabla de diferencia de medias entre Train y Test:\n",
      "       Media Train  Media Test  Diferencia\n",
      "edad        41.242      40.638       0.604\n",
      "edad2     1849.440    1793.362      56.078\n",
      "educ         0.996       1.011      -0.015\n",
      "mujer        0.446       0.461      -0.015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Cargar la base de datos\n",
    "ruta = \"C:/Users/Urano/Downloads/base_respondieron_patagonia.csv\"\n",
    "datos = pd.read_csv(ruta, low_memory=False)\n",
    "\n",
    "# --- 2. Crear variables necesarias\n",
    "datos['edad'] = pd.to_numeric(datos['CH06'], errors='coerce')\n",
    "datos['edad2'] = datos['edad'] ** 2\n",
    "datos['mujer'] = datos['CH04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['educ'] = pd.to_numeric(datos['PP07H'], errors='coerce')\n",
    "\n",
    "# --- 3. Crear variable binaria 'ocupacion'\n",
    "# (1 = ocupado, 2 = desocupado, los dem√°s se descartan)\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})\n",
    "datos['ocupacion'] = pd.to_numeric(datos['ocupacion'], errors='coerce')\n",
    "\n",
    "# --- 4. Mostrar estado general\n",
    "print(\"\\nüîé Valores NO nulos por variable:\")\n",
    "print(datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']].notnull().sum())\n",
    "\n",
    "print(\"\\nüìå Valores √∫nicos en 'ocupacion':\")\n",
    "print(datos['ocupacion'].value_counts(dropna=False))\n",
    "\n",
    "# --- 5. Armar base limpia\n",
    "modelo = datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']].dropna()\n",
    "print(f\"\\nüìä Filas v√°lidas despu√©s de limpieza: {len(modelo)}\")\n",
    "\n",
    "# --- 6. Separar X e y\n",
    "X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "y = modelo['ocupacion']\n",
    "\n",
    "# --- 7. Divisi√≥n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=444\n",
    ")\n",
    "\n",
    "# --- 8. Tabla de diferencia de medias\n",
    "media_train = X_train.mean().rename(\"Media Train\")\n",
    "media_test = X_test.mean().rename(\"Media Test\")\n",
    "diferencia = (media_train - media_test).rename(\"Diferencia\")\n",
    "\n",
    "tabla_medias = pd.concat([media_train, media_test, diferencia], axis=1)\n",
    "print(\"\\nüìä Tabla de diferencia de medias entre Train y Test:\")\n",
    "print(tabla_medias.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd9eb3-5a7d-4762-8dff-b2948bb52ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
