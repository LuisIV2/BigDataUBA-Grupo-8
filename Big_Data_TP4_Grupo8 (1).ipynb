{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50d3ed70-30a9-4c14-a38e-90a373b85fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Valores NO nulos por variable:\n",
      "edad         5523\n",
      "edad2        5523\n",
      "educ         2407\n",
      "mujer        5523\n",
      "ocupacion    5523\n",
      "dtype: int64\n",
      "\n",
      "ðŸ“Œ Valores Ãºnicos en 'ocupacion':\n",
      "ocupacion\n",
      "NaN    3264\n",
      "1.0    2407\n",
      "3.0    2357\n",
      "4.0     644\n",
      "2.0     115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸ“Š Filas vÃ¡lidas despuÃ©s de limpieza: 2407\n",
      "\n",
      "ðŸ“Š Tabla de diferencia de medias entre Train y Test:\n",
      "       Media Train  Media Test  Diferencia\n",
      "edad        41.242      40.638       0.604\n",
      "edad2     1849.440    1793.362      56.078\n",
      "educ         0.996       1.011      -0.015\n",
      "mujer        0.446       0.461      -0.015\n",
      "+-------------+-------------------+---------------------+---------------------+------------------------+------------------------+\n",
      "| Variable    | Modelo i          | Modelo ii           | Modelo iii          | Modelo iv              | Modelo v               |\n",
      "+=============+===================+=====================+=====================+========================+========================+\n",
      "| Hora social |                   |                     |                     |                        | -30391.369 (6398.83)   |\n",
      "+-------------+-------------------+---------------------+---------------------+------------------------+------------------------+\n",
      "| edad        | 3199.737 (889.83) | 17875.539 (5273.26) | 17094.704 (5291.43) | 19284.784 (5259.79)    | 18884.674 (5218.49)    |\n",
      "+-------------+-------------------+---------------------+---------------------+------------------------+------------------------+\n",
      "| edad2       |                   | -170.386 (60.35)    | -165.015 (60.4)     | -190.753 (60.05)       | -186.188 (59.57)       |\n",
      "+-------------+-------------------+---------------------+---------------------+------------------------+------------------------+\n",
      "| educ        |                   |                     | -30736.72 (18504.9) | -20693.488 (18431.39)  | -10550.719 (18385.3)   |\n",
      "+-------------+-------------------+---------------------+---------------------+------------------------+------------------------+\n",
      "| jefe/a      |                   |                     |                     |                        | 66565.176 (25826.38)   |\n",
      "+-------------+-------------------+---------------------+---------------------+------------------------+------------------------+\n",
      "| mujer       |                   |                     |                     | -119527.465 (21512.14) | -124786.039 (21378.12) |\n",
      "+-------------+-------------------+---------------------+---------------------+------------------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# --- 1. Cargar la base de datos\n",
    "ruta = \"C:/Users/Choco/Downloads/base_respondieron_patagonia.csv\"\n",
    "datos = pd.read_csv(ruta, low_memory=False)\n",
    "\n",
    "# --- 2. Crear variables necesarias\n",
    "datos['edad'] = pd.to_numeric(datos['CH06'], errors='coerce')\n",
    "datos['edad2'] = datos['edad'] ** 2\n",
    "datos['mujer'] = datos['CH04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['educ'] = pd.to_numeric(datos['PP07H'], errors='coerce')\n",
    "\n",
    "# --- 3. Crear variable binaria 'ocupacion'\n",
    "# (1 = ocupado, 2 = desocupado, los demÃ¡s se descartan)\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})\n",
    "datos['ocupacion'] = pd.to_numeric(datos['ocupacion'], errors='coerce')\n",
    "\n",
    "# --- 4. Mostrar estado general\n",
    "print(\"\\nðŸ”Ž Valores NO nulos por variable:\")\n",
    "print(datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']].notnull().sum())\n",
    "\n",
    "print(\"\\nðŸ“Œ Valores Ãºnicos en 'ocupacion':\")\n",
    "print(datos['ocupacion'].value_counts(dropna=False))\n",
    "\n",
    "# --- 5. Armar base limpia\n",
    "modelo = datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion']].dropna()\n",
    "print(f\"\\nðŸ“Š Filas vÃ¡lidas despuÃ©s de limpieza: {len(modelo)}\")\n",
    "\n",
    "# --- 6. Separar X e y\n",
    "X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "y = modelo['ocupacion']\n",
    "\n",
    "# --- 7. DivisiÃ³n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=444\n",
    ")\n",
    "\n",
    "# --- 8. Tabla de diferencia de medias\n",
    "media_train = X_train.mean().rename(\"Media Train\")\n",
    "media_test = X_test.mean().rename(\"Media Test\")\n",
    "diferencia = (media_train - media_test).rename(\"Diferencia\")\n",
    "\n",
    "tabla_medias = pd.concat([media_train, media_test, diferencia], axis=1)\n",
    "print(\"\\nðŸ“Š Tabla de diferencia de medias entre Train y Test:\")\n",
    "print(tabla_medias.round(3))\n",
    "#Cargar la base de datos\n",
    "ruta = \"C:/Users/Choco/Downloads/base_respondieron_patagonia.csv\"\n",
    "datos = pd.read_csv(ruta, low_memory=False)\n",
    "\n",
    "#Crear variables necesarias\n",
    "datos['edad'] = pd.to_numeric(datos['CH06'], errors='coerce')\n",
    "datos['edad2'] = datos['edad'] ** 2\n",
    "datos['mujer'] = datos['CH04'].replace({1: 0, 2: 1, 9: np.nan})\n",
    "datos['educ'] = pd.to_numeric(datos['PP07H'], errors='coerce')\n",
    "datos['ocupacion'] = datos['ESTADO'].replace({1: 1, 2: 0})\n",
    "datos['ocupacion'] = pd.to_numeric(datos['ocupacion'], errors='coerce')\n",
    "datos['salario_semanal'] = pd.to_numeric(datos['P21'], errors='coerce')\n",
    "datos['Hora social'] = pd.to_numeric(datos['CH08'], errors='coerce')\n",
    "datos[ 'jefe/a' ] = pd.to_numeric(datos['CH16'], errors='coerce')\n",
    "\n",
    "#Armar base limpia\n",
    "modelo = datos[['edad', 'edad2', 'educ', 'mujer', 'ocupacion', 'salario_semanal', 'Hora social', 'jefe/a']].dropna(subset=['ocupacion', 'salario_semanal'])\n",
    "\n",
    "#Separar X e y\n",
    "X = modelo[['edad', 'edad2', 'educ', 'mujer']]\n",
    "y = modelo['ocupacion']\n",
    "\n",
    "#DivisiÃ³n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=444)\n",
    "\n",
    "#Estimar modelos de regresiÃ³n lineal para ocupados\n",
    "ocupados_train = modelo[(modelo['ocupacion'] == 1) & (modelo.index.isin(X_train.index))]\n",
    "X_train_ocupados = ocupados_train[['edad', 'edad2', 'educ', 'mujer', 'Hora social', 'jefe/a']]\n",
    "y_train_ocupados = ocupados_train['salario_semanal']\n",
    "\n",
    "#Modelos de regresiÃ³n lineal\n",
    "modelos = [\n",
    "    {'nombre': 'Modelo i', 'variables': ['edad']},\n",
    "    {'nombre': 'Modelo ii', 'variables': ['edad', 'edad2']},\n",
    "    {'nombre': 'Modelo iii', 'variables': ['edad', 'edad2', 'educ']},\n",
    "    {'nombre': 'Modelo iv', 'variables': ['edad', 'edad2', 'educ', 'mujer']},\n",
    "    {'nombre': 'Modelo v', 'variables': ['edad', 'edad2', 'educ', 'mujer', 'Hora social', 'jefe/a']}\n",
    "]\n",
    "\n",
    "#Imprimir resultados\n",
    "variables = set()\n",
    "for modelo in modelos:\n",
    "    variables.update(modelo['variables'])\n",
    "variables = sorted(list(variables))\n",
    "\n",
    "tabla = []\n",
    "for variable in variables:\n",
    "    fila = []\n",
    "    for modelo in modelos:\n",
    "        X_modelo = sm.add_constant(X_train_ocupados[modelo['variables']])\n",
    "        model = sm.OLS(y_train_ocupados, X_modelo).fit()\n",
    "        params = model.params.round(3)\n",
    "        se = model.bse.round(2)\n",
    "        if variable in params.index:\n",
    "            fila.append(str(params[variable]) + \" (\" + str(se[variable]) + \")\")\n",
    "        else:\n",
    "            fila.append(\"\")\n",
    "    tabla.append([variable] + fila)\n",
    "\n",
    "headers = [\"Variable\"] + [modelo['nombre'] for modelo in modelos]\n",
    "print(tabulate(tabla, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa85f7b4-ec09-42b0-9a25-835b90b44580",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "     confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af19baa-11a8-4ea8-b204-37901c722dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nro_hogar', 'componente', 'h15', 'ano4', 'trimestre', 'region',\n",
      "       'mas_500', 'aglomerado', 'pondera', 'ch03',\n",
      "       ...\n",
      "       'GDECIFR', 'PDECIFR', 'ADECIFR', 'DECCFR', 'IDECCFR', 'RDECCFR',\n",
      "       'GDECCFR', 'PDECCFR', 'ADECCFR', 'PONDIH'],\n",
      "      dtype='object', length=350)\n",
      "   nro_hogar componente h15    ano4       trimestre      region mas_500  \\\n",
      "0        1.0        1.0  SÃ­  2004.0  1er. Trimestre  PatagÃ³nica       N   \n",
      "1        1.0        1.0  SÃ­  2004.0  1er. Trimestre  PatagÃ³nica       N   \n",
      "2        1.0        2.0  SÃ­  2004.0  1er. Trimestre  PatagÃ³nica       N   \n",
      "3        1.0        1.0  SÃ­  2004.0  1er. Trimestre  PatagÃ³nica       N   \n",
      "4        1.0        2.0  SÃ­  2004.0  1er. Trimestre  PatagÃ³nica       N   \n",
      "\n",
      "                        aglomerado  pondera            ch03  ... GDECIFR  \\\n",
      "0  Comodoro Rivadavia - Rada Tilly    150.0            Jefe  ...     NaN   \n",
      "1  Comodoro Rivadavia - Rada Tilly    120.0            Jefe  ...     NaN   \n",
      "2  Comodoro Rivadavia - Rada Tilly    120.0  CÃ³nyuge/Pareja  ...     NaN   \n",
      "3  Comodoro Rivadavia - Rada Tilly    223.0            Jefe  ...     NaN   \n",
      "4  Comodoro Rivadavia - Rada Tilly    223.0  CÃ³nyuge/Pareja  ...     NaN   \n",
      "\n",
      "  PDECIFR ADECIFR DECCFR IDECCFR RDECCFR GDECCFR PDECCFR ADECCFR PONDIH  \n",
      "0     NaN     NaN    NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
      "1     NaN     NaN    NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
      "2     NaN     NaN    NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
      "3     NaN     NaN    NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
      "4     NaN     NaN    NaN     NaN     NaN     NaN     NaN     NaN    NaN  \n",
      "\n",
      "[5 rows x 350 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3404/2434044526.py:1: DtypeWarning: Columns (1,2,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,43,44,45,46,47,48,49,50,55,56,57,58,62,63,64,65,66,67,68,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,99,100,101,102,103,104,105,106,107,108,109,113,114,115,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,141,161,168,171,172,173,182,187,279) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('base_respondieron_patagonia.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('base_respondieron_patagonia.csv')\n",
    "\n",
    "# Verifica que estÃ© cargado y cÃ³mo se llaman las columnas\n",
    "print(df.columns)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58b6d4a7-cab5-4ae5-b05a-5fbde0e27622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nro_hogar', 'componente', 'h15', 'ano4', 'trimestre', 'region',\n",
      "       'mas_500', 'aglomerado', 'pondera', 'ch03',\n",
      "       ...\n",
      "       'GDECIFR', 'PDECIFR', 'ADECIFR', 'DECCFR', 'IDECCFR', 'RDECCFR',\n",
      "       'GDECCFR', 'PDECCFR', 'ADECCFR', 'PONDIH'],\n",
      "      dtype='object', length=350)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3404/3961420644.py:3: DtypeWarning: Columns (1,2,4,5,6,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,43,44,45,46,47,48,49,50,55,56,57,58,62,63,64,65,66,67,68,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,99,100,101,102,103,104,105,106,107,108,109,113,114,115,119,120,121,122,123,124,125,126,127,128,130,131,132,133,134,135,141,161,168,171,172,173,182,187,279) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"base_respondieron_patagonia.csv\")\n"
     ]
    }
   ],
   "source": [
    "# AsegÃºrate de haber cargado el DataFrame 'df'\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"base_respondieron_patagonia.csv\")\n",
    "\n",
    "# Verifica los nombres de las columnas\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b138d092-eff4-474e-8767-67a1678e7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separar variables predictoras (X) y variables objetivo (y)\n",
    "X = df.drop(columns='componente') # Usa el nombre exacto que aparece en print(df.columns)\n",
    "y = df['componente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d20fad5-223c-4018-9094-32c00db8584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir variables categÃ³ricas a nÃºmericas\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index] # Alinea y con las filas de X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e35b197d-0c88-4fd6-beca-45b0d1954b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TamaÃ±o de X: (0, 3435)\n",
      "TamaÃ±o de y: (0,)\n"
     ]
    }
   ],
   "source": [
    "print(\"TamaÃ±o de X:\", X.shape)\n",
    "print(\"TamaÃ±o de y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5370dbd4-0827-491d-b460-afdecd104b97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m      3\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m279\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2619\u001b[0m )\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-panel-2023.05-py310/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2277\u001b[0m     )\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=279)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff04c9-eba6-4feb-828f-ab9fbc2cfe4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1202b7-ef53-46ad-a68c-d78715d33cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa486e1-7a79-4ad8-a649-4b69fb515bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
