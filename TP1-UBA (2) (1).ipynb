{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "Dh8MkXaG-c9Y",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Big Data y Machine Learning (UBA) -  2025\n",
    "\n",
    "## Trabajo Práctico 1: Jugando con APIs y WebScraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhBlm6mZ-c9e"
   },
   "source": [
    "### Reglas de formato y presentación\n",
    "- El trabajo debe estar debidamente documentado comentado (utilizando #) para que tanto los docentes como sus compañeros puedan comprender el código fácilmente.\n",
    "\n",
    "- El mismo debe ser completado en este Jupyter Notebook y entregado como tal, es decir en un archivo .ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEjGaa4U-c9g"
   },
   "source": [
    "### Fecha de entrega:\n",
    "Viernes 4 de Abril a las 13:00 hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9TU2y7E-c9h"
   },
   "source": [
    "### Modalidad de entrega\n",
    "- Al finalizar el trabajo práctico deben hacer un último <i>commit</i> en su repositorio de GitHub llamado “Entrega final del tp”. \n",
    "- Asegurense de haber creado una carpeta llamada TP1. Este Jupyter Notebook y el correspondiente al TP1 deben estar dentro de esa carpeta.\n",
    "- También deben enviar el link de su repositorio -para que pueda ser clonado y corregido- a mi correo 25RO35480961@campus.economicas.uba.ar. Usar de asunto de email <i>\"Big Data - TP 1 - Grupo #\"</i> y nombrar el archivo <i>\"TP1_Grupo #\"</i> donde # es el número de grupo que le fue asignado.\n",
    "- La última versión en el repositorio es la que será evaluada. Por lo que es importante que: \n",
    "    - No envien el correo hasta no haber terminado y estar seguros de que han hecho el <i>commit y push</i> a la versión final que quieren entregar. \n",
    "    - No hagan nuevos <i>push</i> despues de haber entregado su versión final. Esto generaría confusión acerca de que versión es la que quieren que se les corrija.\n",
    "- En resumen, la carpeta del repositorio debe incluir:\n",
    "    - El codigo\n",
    "    - Un documento Word (Parte A) donde esten las figuras y una breve descripción de las mismas.\n",
    "    - El excel con los links webscrappeados (Parte B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXbrPraa-c9i"
   },
   "source": [
    "#### Ejercicio 1 - Jugando con APIs\n",
    "Usando la API del Banco Mundial [link](https://wbdata.readthedocs.io/en/stable/) , obtener dos series de indicadores para dos paises a elección en una consulta de búsqueda. Pueden buscar serie de indicadores de su interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Población de Argentina y Brasil (2000-2020)\n",
      " Año  Argentina    Brasil\n",
      "2020   45191965 208660842\n",
      "2019   44973465 207455459\n",
      "2018   44654882 206107261\n",
      "2017   44288894 204703445\n",
      "2016   43900313 203218114\n",
      "2015   43477012 201675532\n",
      "2014   43024071 200085127\n",
      "2013   42582455 198478299\n",
      "2012   42161721 196876111\n",
      "2011   41730660 195284734\n",
      "2010   41288694 193701929\n",
      "2009   40854831 192079951\n",
      "2008   40424148 190367302\n",
      "2007   40016763 188552320\n",
      "2006   39622115 186653106\n",
      "2005   39216789 184688101\n",
      "2004   38815916 182675143\n",
      "2003   38424282 180622688\n",
      "2002   38029349 178503484\n",
      "2001   37624825 176301203\n",
      "2000   37213984 174018282\n"
     ]
    }
   ],
   "source": [
    "# Resolver acá\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_arg = \"http://api.worldbank.org/v2/country/arg/indicator/SP.POP.TOTL?format=json&date=2000:2020&per_page=1000\"\n",
    "url_bra = \"http://api.worldbank.org/v2/country/bra/indicator/SP.POP.TOTL?format=json&date=2000:2020&per_page=1000\"\n",
    "\n",
    "if response_arg := requests.get(url_arg).status_code != 200:\n",
    "    print(\"Error al realizar la consulta para Argentina:\", response_arg)\n",
    "else:\n",
    "    data_arg = requests.get(url_arg).json()[1]\n",
    "    df_arg = pd.DataFrame()\n",
    "    for indicator in data_arg:\n",
    "        df_indicator = pd.DataFrame({\"Año\": [indicator[\"date\"]], \"Argentina\": [indicator[\"value\"]]})\n",
    "        df_arg = pd.concat([df_arg, df_indicator])\n",
    "\n",
    "if response_bra := requests.get(url_bra).status_code != 200:\n",
    "    print(\"Error al realizar la consulta para Brasil:\", response_bra)\n",
    "else:\n",
    "    data_bra = requests.get(url_bra).json()[1]\n",
    "    df_bra = pd.DataFrame()\n",
    "    for indicator in data_bra:\n",
    "        df_indicator = pd.DataFrame({\"Año\": [indicator[\"date\"]], \"Brasil\": [indicator[\"value\"]]})\n",
    "        df_bra = pd.concat([df_bra, df_indicator])\n",
    "\n",
    "df = pd.merge(df_arg, df_bra, on=\"Año\")\n",
    "print(\"Población de Argentina y Brasil (2000-2020)\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2 - Repaso de Pandas\n",
    "Realicen una estadistica descriptiva de ambas series de indicadores comparando los dos países."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadística descriptiva de la población de Argentina y Brasil (2000-2020)\n",
      "           Argentina          Brasil\n",
      "count          21.00           21.00\n",
      "mean   41,310,339.71  192,890,877.76\n",
      "std     2,559,116.75   10,699,066.97\n",
      "min    37,213,984.00  174,018,282.00\n",
      "25%    39,216,789.00  184,688,101.00\n",
      "50%    41,288,694.00  193,701,929.00\n",
      "75%    43,477,012.00  201,675,532.00\n",
      "max    45,191,965.00  208,660,842.00\n",
      "\n",
      "Media de la población de Argentina: 41,310,339.71 millones de habitantes\n",
      "Media de la población de Brasil: 192,890,877.76 millones de habitantes\n",
      "\n",
      "Mediana de la población de Argentina: 41,288,694.00 millones de habitantes\n",
      "Mediana de la población de Brasil: 193,701,929.00 millones de habitantes\n",
      "\n",
      "Desviación estándar de la población de Argentina: 2,559,116.75 millones de habitantes\n",
      "Desviación estándar de la población de Brasil: 10,699,066.97 millones de habitantes\n",
      "\n",
      "Varianza de la población de Argentina: 6,549,078,525,399.31 millones de habitantes\n",
      "Varianza de la población de Brasil: 114,470,034,034,294.88 millones de habitantes\n"
     ]
    }
   ],
   "source": [
    "# Resolver acá\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url_arg = \"http://api.worldbank.org/v2/country/arg/indicator/SP.POP.TOTL?format=json&date=2000:2020&per_page=1000\"\n",
    "url_bra = \"http://api.worldbank.org/v2/country/bra/indicator/SP.POP.TOTL?format=json&date=2000:2020&per_page=1000\"\n",
    "\n",
    "if response_arg := requests.get(url_arg).status_code != 200:\n",
    "    print(\"Error al realizar la consulta para Argentina:\", response_arg)\n",
    "else:\n",
    "    data_arg = requests.get(url_arg).json()[1]\n",
    "    df_arg = pd.DataFrame()\n",
    "    for indicator in data_arg:\n",
    "        df_indicator = pd.DataFrame({\"Año\": [indicator[\"date\"]], \"Argentina\": [indicator[\"value\"]]})\n",
    "        df_arg = pd.concat([df_arg, df_indicator])\n",
    "\n",
    "if response_bra := requests.get(url_bra).status_code != 200:\n",
    "    print(\"Error al realizar la consulta para Brasil:\", response_bra)\n",
    "else:\n",
    "    data_bra = requests.get(url_bra).json()[1]\n",
    "    df_bra = pd.DataFrame()\n",
    "    for indicator in data_bra:\n",
    "        df_indicator = pd.DataFrame({\"Año\": [indicator[\"date\"]], \"Brasil\": [indicator[\"value\"]]})\n",
    "        df_bra = pd.concat([df_bra, df_indicator])\n",
    "\n",
    "df = pd.merge(df_arg, df_bra, on=\"Año\")\n",
    "estadistica_descriptiva = df.describe()\n",
    "print(\"Estadística descriptiva de la población de Argentina y Brasil (2000-2020)\")\n",
    "print(estadistica_descriptiva.apply(lambda x: x.apply(lambda y: format(y, \",.2f\"))))\n",
    "\n",
    "media_arg = df['Argentina'].mean()\n",
    "media_bra = df['Brasil'].mean()\n",
    "print(\"\\nMedia de la población de Argentina:\", format(media_arg, \",.2f\"), \"millones de habitantes\")\n",
    "print(\"Media de la población de Brasil:\", format(media_bra, \",.2f\"), \"millones de habitantes\")\n",
    "\n",
    "mediana_arg = df['Argentina'].median()\n",
    "mediana_bra = df['Brasil'].median()\n",
    "print(\"\\nMediana de la población de Argentina:\", format(mediana_arg, \",.2f\"), \"millones de habitantes\")\n",
    "print(\"Mediana de la población de Brasil:\", format(mediana_bra, \",.2f\"), \"millones de habitantes\")\n",
    "\n",
    "desviacion_estandar_arg = df['Argentina'].std()\n",
    "desviacion_estandar_bra = df['Brasil'].std()\n",
    "print(\"\\nDesviación estándar de la población de Argentina:\", format(desviacion_estandar_arg, \",.2f\"), \"millones de habitantes\")\n",
    "print(\"Desviación estándar de la población de Brasil:\", format(desviacion_estandar_bra, \",.2f\"), \"millones de habitantes\")\n",
    "\n",
    "varianza_arg = df['Argentina'].var()\n",
    "varianza_bra = df['Brasil'].var()\n",
    "print(\"\\nVarianza de la población de Argentina:\", format(varianza_arg, \",.2f\"), \"millones de habitantes\")\n",
    "print(\"Varianza de la población de Brasil:\", format(varianza_bra, \",.2f\"), \"millones de habitantes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3 - Practicando con Matplotlib\n",
    "Armen dos gráficos distintos usando la librería Matplotlib (repasen Clase 4). Uno programandolo con el estilo *pyplot* y otro gráfico de estilo *orientada a objetos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolver acá estilo pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolver acá estilo orientado-objetos \n",
    "# Tip: aprovechar este estilo de programar una figura para hacerlo más lindo \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "De la página de noticias del [diario La Nación](https://www.lanacion.com.ar/) o cualquier diario que les interese, utilicen herramientas de web scraping para obtener los **links** de las noticias de la portada. Guarden los links obtenidos en un dataframe y expórtenlo a un archivo de excel.\n",
    "\n",
    "Nota 1: es posible que logren obtener los links a las noticias sin el dominio: \"https://www.lanacion.com.ar/\". De ser así, concatenen el dominio a la ruta del link obtenido, tal que se obtenga un link al que se pueda acceder. Es decir, que las cadenas de caracteres finales tendrán la forma: https://www.lanacion.com.ar/*texto_obtenido*)\n",
    "\n",
    "Nota 2: junto con su entrega, adjunten una captura de la página de noticias al momento de correr su código. Eso servirá al momento de la corrección para verificar que los links obtenidos hacen referencia a las noticias de ese día y hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\choco\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\choco\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\choco\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Los links de noticias se han guardado en 'links_noticias_lanacion.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la portada de La Nación\n",
    "URL = \"https://www.lanacion.com.ar/\"\n",
    "\n",
    "# Realizar la solicitud HTTP\n",
    "response = requests.get(URL)\n",
    "if response.status_code == 200:\n",
    "    # Parsear el contenido HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Encontrar todos los enlaces de noticias\n",
    "    links = []\n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        href = a_tag['href']\n",
    "        if '/nota/' in href or '/politica/' in href or '/economia/' in href:  \n",
    "            if not href.startswith(\"http\"):\n",
    "                href = \"https://www.lanacion.com.ar\" + href  \n",
    "            links.append(href)\n",
    "    \n",
    "    # Guardar en un DataFrame y exportar a Excel\n",
    "    df = pd.DataFrame(links, columns=[\"Links\"])\n",
    "    df.to_excel(\"links_noticias_lanacion.xlsx\", index=False)\n",
    "    print(\"✅ Los links de noticias se han guardado en 'links_noticias_lanacion.xlsx'.\")\n",
    "else:\n",
    "    print(\"❌ No se pudo obtener la página. Verifica la URL o tu conexión a internet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "TP1 - Parte 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
