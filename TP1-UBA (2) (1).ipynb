{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "Dh8MkXaG-c9Y",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Big Data y Machine Learning (UBA) -  2025\n",
    "\n",
    "## Trabajo Práctico 1: Jugando con APIs y WebScraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhBlm6mZ-c9e"
   },
   "source": [
    "### Reglas de formato y presentación\n",
    "- El trabajo debe estar debidamente documentado comentado (utilizando #) para que tanto los docentes como sus compañeros puedan comprender el código fácilmente.\n",
    "\n",
    "- El mismo debe ser completado en este Jupyter Notebook y entregado como tal, es decir en un archivo .ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEjGaa4U-c9g"
   },
   "source": [
    "### Fecha de entrega:\n",
    "Viernes 4 de Abril a las 13:00 hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9TU2y7E-c9h"
   },
   "source": [
    "### Modalidad de entrega\n",
    "- Al finalizar el trabajo práctico deben hacer un último <i>commit</i> en su repositorio de GitHub llamado “Entrega final del tp”. \n",
    "- Asegurense de haber creado una carpeta llamada TP1. Este Jupyter Notebook y el correspondiente al TP1 deben estar dentro de esa carpeta.\n",
    "- También deben enviar el link de su repositorio -para que pueda ser clonado y corregido- a mi correo 25RO35480961@campus.economicas.uba.ar. Usar de asunto de email <i>\"Big Data - TP 1 - Grupo #\"</i> y nombrar el archivo <i>\"TP1_Grupo #\"</i> donde # es el número de grupo que le fue asignado.\n",
    "- La última versión en el repositorio es la que será evaluada. Por lo que es importante que: \n",
    "    - No envien el correo hasta no haber terminado y estar seguros de que han hecho el <i>commit y push</i> a la versión final que quieren entregar. \n",
    "    - No hagan nuevos <i>push</i> despues de haber entregado su versión final. Esto generaría confusión acerca de que versión es la que quieren que se les corrija.\n",
    "- En resumen, la carpeta del repositorio debe incluir:\n",
    "    - El codigo\n",
    "    - Un documento Word (Parte A) donde esten las figuras y una breve descripción de las mismas.\n",
    "    - El excel con los links webscrappeados (Parte B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXbrPraa-c9i"
   },
   "source": [
    "#### Ejercicio 1 - Jugando con APIs\n",
    "Usando la API del Banco Mundial [link](https://wbdata.readthedocs.io/en/stable/) , obtener dos series de indicadores para dos paises a elección en una consulta de búsqueda. Pueden buscar serie de indicadores de su interés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de Inflación Anual en Argentina y Uruguay (2000-2020)\n",
      "Año\tArgentina\t\tUruguay\n",
      "2020\t4356.42\t\t136.52\n",
      "2019\t3109.88\t\t123.02\n",
      "2018\t2084.43\t\t113.63\n",
      "2017\t1467.56\t\t105.68\n",
      "2016\t1164.67\t\t100.0\n",
      "2015\t825.31\t\t92.45\n",
      "2014\t652.01\t\t84.16\n",
      "2013\t464.78\t\t76.35\n",
      "2012\t374.98\t\t70.05\n",
      "2011\t306.57\t\t64.02\n",
      "2010\t247.82\t\t58.27\n",
      "2009\t204.96\t\t55.1 \n",
      "2008\t177.64\t\t50.73\n",
      "2007\t144.22\t\t46.58\n",
      "2006\t125.48\t\t42.23\n",
      "2005\t110.32\t\t39.31\n",
      "2004\t100.0\t\t39.05\n",
      "2003\t84.49\t\t35.46\n",
      "2002\t76.46\t\t30.43\n",
      "2001\t58.57\t\t27.02\n",
      "2000\t59.21\t\t25.78\n"
     ]
    }
   ],
   "source": [
    "# Resolver acá\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "URL_BASE = \"http://api.worldbank.org/v2/\"\n",
    "PAIS_ARGENTINA = \"ARG\"\n",
    "PAIS_URUGUAY = \"URY\"\n",
    "INDICADOR_INFLACION = \"NY.GDP.DEFL.ZS\"\n",
    "FECHA_INICIO = \"2000\"\n",
    "FECHA_FIN = \"2020\"\n",
    "def obtener_datos(pais, indicador):\n",
    "    url = f\"{URL_BASE}country/{pais}/indicator/{indicador}?date={FECHA_INICIO}:{FECHA_FIN}&format=json\"\n",
    "    respuesta = requests.get(url)\n",
    "    datos = respuesta.json()[1]\n",
    "    df = pd.DataFrame(datos)\n",
    "    return df[[\"date\", \"value\"]]\n",
    "tasa_inflacion_argentina = obtener_datos(PAIS_ARGENTINA, INDICADOR_INFLACION)\n",
    "tasa_inflacion_uruguay = obtener_datos(PAIS_URUGUAY, INDICADOR_INFLACION)\n",
    "print(\"Tasa de Inflación Anual en Argentina y Uruguay (2000-2020)\")\n",
    "print(\"Año\\tArgentina\\t\\tUruguay\")\n",
    "for i in range(len(tasa_inflacion_argentina)):\n",
    "    print(f\"{tasa_inflacion_argentina.iloc[i]['date']}\\t{round(tasa_inflacion_argentina.iloc[i]['value'], 2)}\\t\\t{round(tasa_inflacion_uruguay.iloc[i]['value'], 2):<5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2 - Repaso de Pandas\n",
    "Realicen una estadistica descriptiva de ambas series de indicadores comparando los dos países."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadística descriptiva de la tasa de inflación en Argentina y Uruguay\n",
      "Argentina:\n",
      "count      21.000000\n",
      "mean      771.227531\n",
      "std      1135.444195\n",
      "min        58.565676\n",
      "25%       110.317511\n",
      "50%       247.824346\n",
      "75%       825.310738\n",
      "max      4356.419109\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Uruguay:\n",
      "count     21.000000\n",
      "mean      67.421276\n",
      "std       33.514599\n",
      "min       25.777408\n",
      "25%       39.312836\n",
      "50%       58.268562\n",
      "75%       92.450956\n",
      "max      136.518065\n",
      "Name: value, dtype: float64\n",
      "\n",
      "Media de la tasa de inflación en Argentina: 771.23%\n",
      "Media de la tasa de inflación en Uruguay: 67.42%\n",
      "La tasa de inflación en Argentina es mayor que en Uruguay.\n"
     ]
    }
   ],
   "source": [
    "# Resolver acá\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Constantes\n",
    "URL_BASE = \"http://api.worldbank.org/v2/\"\n",
    "PAIS_ARGENTINA = \"ARG\"\n",
    "PAIS_URUGUAY = \"URY\"\n",
    "INDICADOR_INFLACION = \"NY.GDP.DEFL.ZS\"\n",
    "FECHA_INICIO = \"2000\"\n",
    "FECHA_FIN = \"2020\"\n",
    "\n",
    "def obtener_datos(pais, indicador):\n",
    "    url = f\"{URL_BASE}country/{pais}/indicator/{indicador}?date={FECHA_INICIO}:{FECHA_FIN}&format=json\"\n",
    "    respuesta = requests.get(url)\n",
    "    datos = respuesta.json()[1]\n",
    "    df = pd.DataFrame(datos)\n",
    "    return df[[\"date\", \"value\"]]\n",
    "tasa_inflacion_argentina = obtener_datos(PAIS_ARGENTINA, INDICADOR_INFLACION)\n",
    "tasa_inflacion_uruguay = obtener_datos(PAIS_URUGUAY, INDICADOR_INFLACION)\n",
    "print(\"Estadística descriptiva de la tasa de inflación en Argentina y Uruguay\")\n",
    "print(\"Argentina:\")\n",
    "print(tasa_inflacion_argentina[\"value\"].describe())\n",
    "print(\"\\nUruguay:\")\n",
    "print(tasa_inflacion_uruguay[\"value\"].describe())\n",
    "media_argentina = tasa_inflacion_argentina[\"value\"].mean()\n",
    "media_uruguay = tasa_inflacion_uruguay[\"value\"].mean()\n",
    "print(f\"\\nMedia de la tasa de inflación en Argentina: {media_argentina:.2f}%\")\n",
    "print(f\"Media de la tasa de inflación en Uruguay: {media_uruguay:.2f}%\")\n",
    "if media_argentina > media_uruguay:\n",
    "    print(\"La tasa de inflación en Argentina es mayor que en Uruguay.\")\n",
    "elif media_argentina < media_uruguay:\n",
    "    print(\"La tasa de inflación en Uruguay es mayor que en Argentina.\")\n",
    "else:\n",
    "    print(\"La tasa de inflación en Argentina y Uruguay es igual.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3 - Practicando con Matplotlib\n",
    "Armen dos gráficos distintos usando la librería Matplotlib (repasen Clase 4). Uno programandolo con el estilo *pyplot* y otro gráfico de estilo *orientada a objetos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolver acá estilo pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolver acá estilo orientado-objetos \n",
    "# Tip: aprovechar este estilo de programar una figura para hacerlo más lindo \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4\n",
    "De la página de noticias del [diario La Nación](https://www.lanacion.com.ar/) o cualquier diario que les interese, utilicen herramientas de web scraping para obtener los **links** de las noticias de la portada. Guarden los links obtenidos en un dataframe y expórtenlo a un archivo de excel.\n",
    "\n",
    "Nota 1: es posible que logren obtener los links a las noticias sin el dominio: \"https://www.lanacion.com.ar/\". De ser así, concatenen el dominio a la ruta del link obtenido, tal que se obtenga un link al que se pueda acceder. Es decir, que las cadenas de caracteres finales tendrán la forma: https://www.lanacion.com.ar/*texto_obtenido*)\n",
    "\n",
    "Nota 2: junto con su entrega, adjunten una captura de la página de noticias al momento de correr su código. Eso servirá al momento de la corrección para verificar que los links obtenidos hacen referencia a las noticias de ese día y hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\choco\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\choco\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\choco\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\choco\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Los links de noticias se han guardado en 'links_noticias_lanacion.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL de la portada de La Nación\n",
    "URL = \"https://www.lanacion.com.ar/\"\n",
    "\n",
    "# Realizar la solicitud HTTP\n",
    "response = requests.get(URL)\n",
    "if response.status_code == 200:\n",
    "    # Parsear el contenido HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Encontrar todos los enlaces de noticias\n",
    "    links = []\n",
    "    for a_tag in soup.find_all('a', href=True):\n",
    "        href = a_tag['href']\n",
    "        if '/nota/' in href or '/politica/' in href or '/economia/' in href:  \n",
    "            if not href.startswith(\"http\"):\n",
    "                href = \"https://www.lanacion.com.ar\" + href  \n",
    "            links.append(href)\n",
    "    \n",
    "    # Guardar en un DataFrame y exportar a Excel\n",
    "    df = pd.DataFrame(links, columns=[\"Links\"])\n",
    "    df.to_excel(\"links_noticias_lanacion.xlsx\", index=False)\n",
    "    print(\"✅ Los links de noticias se han guardado en 'links_noticias_lanacion.xlsx'.\")\n",
    "else:\n",
    "    print(\"❌ No se pudo obtener la página. Verifica la URL o tu conexión a internet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "TP1 - Parte 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
